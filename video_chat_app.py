#!/usr/bin/env python3
"""
å®Œæ•´çš„MiniCPM-Vè§†é¢‘èŠå¤©Gradioåº”ç”¨
ä½¿ç”¨å®Œå…¨å»¶è¿ŸåŠ è½½ç­–ç•¥
"""

import os
import gradio as gr
import time
from typing import Optional, Any, Dict, List, Tuple

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DISABLE_TRITON'] = '1'
os.environ['USE_TRITON'] = '0'
os.environ['TRITON_DISABLE'] = '1'
os.environ['DISABLE_FLASH_ATTN'] = '1'
os.environ['PYTORCH_DISABLE_TRITON'] = '1'

class LazyVideoChatApp:
    """å»¶è¿ŸåŠ è½½çš„è§†é¢‘èŠå¤©åº”ç”¨"""
    
    def __init__(self):
        self.service = None
        self.current_video_data = None
        
    def initialize_service(self, max_frames: int = 180, max_packing: int = 3) -> str:
        """åˆå§‹åŒ–æœåŠ¡ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        try:
            # åªæœ‰åœ¨éœ€è¦æ—¶æ‰å¯¼å…¥
            from src.chat_with_video.video_chat_service import VideoChatService
            
            print("æ­£åœ¨åˆå§‹åŒ–è§†é¢‘èŠå¤©æœåŠ¡...")
            self.service = VideoChatService(
                model_path='openbmb/MiniCPM-V-4_5',
                device='xpu',
                max_frames=max_frames,
                max_packing=max_packing
            )
            
            # åˆå§‹åŒ–æœåŠ¡
            success = self.service.initialize()
            
            if success:
                info = self.service.get_system_info()
                return f"""âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼

ğŸ”§ ç³»ç»Ÿé…ç½®:
- æ¨¡å‹: {info.get('model_path', 'N/A')}
- è®¾å¤‡: {info.get('device', 'N/A')} 
- XPUå¯ç”¨: {info.get('xpu_available', False)}
- è®¾å¤‡æ•°é‡: {info.get('device_count', 0)}

ğŸ“¹ 3Dé‡é‡‡æ ·å™¨é…ç½®:
- æœ€å¤§å¸§æ•°: {info['video_encoder_config']['max_frames']}
- æœ€å¤§æ‰“åŒ…æ•°: {info['video_encoder_config']['max_packing']}

ğŸš€ ç³»ç»Ÿå·²å°±ç»ªï¼"""
            else:
                return "âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥"
                
        except Exception as e:
            import traceback
            return f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\nè¯¦ç»†ä¿¡æ¯:\n{traceback.format_exc()}"
    
    def process_video(self, video_file, fps: int = 5, force_packing: Optional[int] = None) -> str:
        """å¤„ç†è§†é¢‘"""
        if not self.service:
            return "âŒ è¯·å…ˆåˆå§‹åŒ–æœåŠ¡"
        
        if not video_file:
            return "âŒ è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶"
        
        try:
            start_time = time.time()
            
            frames, temporal_ids = self.service.process_video(
                video_path=video_file,
                choose_fps=fps,
                force_packing=force_packing if force_packing and force_packing > 0 else None
            )
            
            self.current_video_data = (frames, temporal_ids)
            process_time = time.time() - start_time
            
            return f"""âœ… è§†é¢‘å¤„ç†å®Œæˆï¼

ğŸ“Š å¤„ç†ç»“æœ:
- æå–å¸§æ•°: {len(frames)}
- æ—¶åºç»„æ•°: {len(temporal_ids)} 
- å¤„ç†è€—æ—¶: {process_time:.2f}ç§’

ğŸ’¬ ç°åœ¨å¯ä»¥å¼€å§‹èŠå¤©äº†ï¼"""
            
        except Exception as e:
            return f"âŒ è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}"
    
    def chat_with_video(self, question: str, max_tokens: int = 2048, temperature: float = 0.7) -> str:
        """ä¸è§†é¢‘èŠå¤©"""
        if not self.service:
            return "âŒ è¯·å…ˆåˆå§‹åŒ–æœåŠ¡"
            
        if not self.current_video_data:
            return "âŒ è¯·å…ˆå¤„ç†è§†é¢‘"
            
        if not question.strip():
            return "âŒ è¯·è¾“å…¥é—®é¢˜"
        
        try:
            frames, temporal_ids = self.current_video_data
            start_time = time.time()
            
            # è°ƒç”¨æœåŠ¡è¿›è¡Œæ¨ç†
            answer = self.service.chat_with_frames(
                frames=frames,
                temporal_ids=temporal_ids,
                question=question,
                max_new_tokens=max_tokens,
                temperature=temperature
            )
            
            inference_time = time.time() - start_time
            return f"""ğŸ¤– AIå›ç­”:
{answer}

â±ï¸ æ¨ç†è€—æ—¶: {inference_time:.2f}ç§’"""
            
        except Exception as e:
            return f"âŒ èŠå¤©å¤±è´¥: {str(e)}"


def create_app():
    """åˆ›å»ºGradioåº”ç”¨"""
    app_instance = LazyVideoChatApp()
    
    with gr.Blocks(title="MiniCPM-V è§†é¢‘èŠå¤©", theme=gr.themes.Default()) as interface:
        gr.Markdown("# ğŸ¥ MiniCPM-V è§†é¢‘èŠå¤© Demo - Intel GPUç‰ˆæœ¬")
        
        with gr.Tab("ğŸ“‹ ç³»ç»Ÿæ§åˆ¶"):
            gr.Markdown("## ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–")
            
            with gr.Row():
                with gr.Column(scale=1):
                    max_frames = gr.Slider(50, 300, value=180, step=10, label="æœ€å¤§å¸§æ•°")
                    max_packing = gr.Slider(1, 6, value=3, step=1, label="æœ€å¤§æ‰“åŒ…æ•°")
                    init_btn = gr.Button("ğŸ”§ åˆå§‹åŒ–æœåŠ¡", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    init_status = gr.Textbox(
                        label="åˆå§‹åŒ–çŠ¶æ€",
                        lines=15,
                        interactive=False,
                        value="ç‚¹å‡»'åˆå§‹åŒ–æœåŠ¡'å¼€å§‹..."
                    )
            
            init_btn.click(
                fn=app_instance.initialize_service,
                inputs=[max_frames, max_packing],
                outputs=[init_status]
            )
        
        with gr.Tab("ğŸ“¹ è§†é¢‘å¤„ç†"):
            gr.Markdown("## ğŸ“¤ è§†é¢‘ä¸Šä¼ ä¸å¤„ç†")
            
            with gr.Row():
                with gr.Column(scale=1):
                    video_file = gr.File(
                        label="é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                        file_types=["video"]
                    )
                    fps_slider = gr.Slider(1, 10, value=5, step=1, label="é‡‡æ ·å¸§ç‡ (FPS)")
                    force_packing_num = gr.Number(
                        label="å¼ºåˆ¶æ‰“åŒ…æ•°é‡ (0=è‡ªåŠ¨)",
                        value=0,
                        minimum=0,
                        maximum=6
                    )
                    process_btn = gr.Button("ğŸ¬ å¤„ç†è§†é¢‘", variant="primary")
                
                with gr.Column(scale=2):
                    process_status = gr.Textbox(
                        label="å¤„ç†çŠ¶æ€",
                        lines=10,
                        interactive=False
                    )
            
            process_btn.click(
                fn=app_instance.process_video,
                inputs=[video_file, fps_slider, force_packing_num],
                outputs=[process_status]
            )
        
        with gr.Tab("ğŸ’¬ è§†é¢‘èŠå¤©"):
            gr.Markdown("## ğŸ¤– ä¸è§†é¢‘è¿›è¡Œæ™ºèƒ½å¯¹è¯")
            
            with gr.Row():
                with gr.Column(scale=1):
                    question_input = gr.Textbox(
                        label="è¾“å…¥é—®é¢˜",
                        placeholder="è¯·æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹...",
                        lines=3
                    )
                    
                    with gr.Row():
                        max_tokens = gr.Slider(512, 4096, value=2048, step=128, label="æœ€å¤§ç”Ÿæˆé•¿åº¦")
                        temperature = gr.Slider(0.1, 1.0, value=0.7, step=0.1, label="åˆ›é€ æ€§")
                    
                    chat_btn = gr.Button("ğŸ’­ å¼€å§‹èŠå¤©", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    chat_output = gr.Textbox(
                        label="AIå›ç­”",
                        lines=15,
                        interactive=False
                    )
            
            chat_btn.click(
                fn=app_instance.chat_with_video,
                inputs=[question_input, max_tokens, temperature],
                outputs=[chat_output]
            )
        
        with gr.Tab("â„¹ï¸ è¯´æ˜"):
            gr.Markdown("""
            ## ğŸ“– ä½¿ç”¨è¯´æ˜
            
            ### æ­¥éª¤1: ç³»ç»Ÿåˆå§‹åŒ–
            1. åœ¨"ç³»ç»Ÿæ§åˆ¶"æ ‡ç­¾é¡µä¸­è°ƒæ•´å‚æ•°
            2. ç‚¹å‡»"åˆå§‹åŒ–æœåŠ¡"æŒ‰é’®
            3. ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½çº¦8GBæ¨¡å‹ï¼‰
            
            ### æ­¥éª¤2: è§†é¢‘å¤„ç†  
            1. åœ¨"è§†é¢‘å¤„ç†"æ ‡ç­¾é¡µä¸Šä¼ è§†é¢‘æ–‡ä»¶
            2. è°ƒæ•´é‡‡æ ·å¸§ç‡å’Œæ‰“åŒ…å‚æ•°
            3. ç‚¹å‡»"å¤„ç†è§†é¢‘"æŒ‰é’®
            
            ### æ­¥éª¤3: å¼€å§‹èŠå¤©
            1. åœ¨"è§†é¢‘èŠå¤©"æ ‡ç­¾é¡µè¾“å…¥é—®é¢˜
            2. è°ƒæ•´ç”Ÿæˆå‚æ•°
            3. ç‚¹å‡»"å¼€å§‹èŠå¤©"æŒ‰é’®
            
            ## ğŸ¯ æ”¯æŒçš„åŠŸèƒ½
            - è§†é¢‘å†…å®¹æè¿°
            - ç»†èŠ‚æå–
            - æƒ…ç»ªåˆ†æ  
            - äººç‰©è¯†åˆ«
            - åœºæ™¯ç†è§£
            
            ## âš¡ Intel Arc GPUåŠ é€Ÿ
            - ä½¿ç”¨Intel Arc 130V GPUè¿›è¡Œæ¨ç†
            - æ”¯æŒ3Dé‡é‡‡æ ·å™¨ä¼˜åŒ–
            - bfloat16ç²¾åº¦ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
            """)
    
    return interface


if __name__ == "__main__":
    print("ğŸŒ å¯åŠ¨MiniCPM-Vè§†é¢‘èŠå¤©åº”ç”¨...")
    
    try:
        interface = create_app()
        
        print("âœ… ç•Œé¢åˆ›å»ºæˆåŠŸ")
        print("ğŸš€ æ­£åœ¨å¯åŠ¨GradioæœåŠ¡...")
        print("ğŸ“ è®¿é—®åœ°å€: http://localhost:7861")
        
        interface.launch(
            server_name="0.0.0.0",
            server_port=7861,
            share=False,
            show_error=True
        )
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()