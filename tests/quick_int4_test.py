#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•INT4æ¨¡å‹
"""
import os
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DISABLE_TRITON'] = '1'
os.environ['USE_TRITON'] = '0'

def test_int4_model():
    try:
        print("ğŸ§ª å¿«é€Ÿæµ‹è¯•INT4æ¨¡å‹...")
        
        from src.chat_with_video.model_loader import MiniCPMVInference
        
        # åˆ›å»ºæ¨ç†å¼•æ“
        print("ğŸ“¦ åˆ›å»ºINT4æ¨ç†å¼•æ“...")
        inference_engine = MiniCPMVInference()
        
        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸš€ åˆå§‹åŒ–æ¨¡å‹...")
        inference_engine.initialize()
        
        print("âœ… INT4æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # ç®€å•æ¨ç†æµ‹è¯•
        print("ğŸ§ª æµ‹è¯•æ¨ç†...")
        test_msgs = [{'role': 'user', 'content': ['ä½ å¥½']}]
        
        response = inference_engine.chat(
            msgs=test_msgs,
            max_new_tokens=20,
            temperature=0.7
        )
        
        print(f"âœ… æ¨ç†æˆåŠŸ! å›ç­”: {response}")
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_int4_model()
    print(f"\nç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")