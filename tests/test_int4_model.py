#!/usr/bin/env python3
"""
æµ‹è¯•MiniCPM-V-4.5-int4é‡åŒ–ç‰ˆæœ¬
éªŒè¯INT4æ¨¡å‹çš„åŠ è½½ã€æ¨ç†å’Œæ€§èƒ½
"""

import os
import torch
import time

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DISABLE_TRITON'] = '1'
os.environ['USE_TRITON'] = '0'
os.environ['TRITON_DISABLE'] = '1'
os.environ['DISABLE_FLASH_ATTN'] = '1'
os.environ['PYTORCH_DISABLE_TRITON'] = '1'

def test_int4_model_loading():
    """æµ‹è¯•INT4æ¨¡å‹åŠ è½½"""
    try:
        print("ğŸ”§ æµ‹è¯•MiniCPM-V-4.5-int4é‡åŒ–ç‰ˆæœ¬...")
        
        # æ¸…ç†XPUç¼“å­˜
        if hasattr(torch.xpu, 'empty_cache'):
            torch.xpu.empty_cache()
            print("âœ… XPUç¼“å­˜å·²æ¸…ç†")
        
        # å¯¼å…¥INT4æ¨¡å‹åŠ è½½å™¨
        from src.chat_with_video.model_loader import MiniCPMVInference
        
        # åˆ›å»ºæ¨ç†å¼•æ“ - ä½¿ç”¨é»˜è®¤çš„int4è·¯å¾„
        print("ğŸ“¦ åˆ›å»ºINT4æ¨ç†å¼•æ“...")
        start_time = time.time()
        
        inference_engine = MiniCPMVInference()  # é»˜è®¤ä½¿ç”¨int4ç‰ˆæœ¬
        
        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸš€ åˆå§‹åŒ–INT4æ¨¡å‹...")
        inference_engine.initialize()
        
        init_time = time.time() - start_time
        print(f"â±ï¸ æ¨¡å‹åˆå§‹åŒ–è€—æ—¶: {init_time:.2f}ç§’")
        
        # æ£€æŸ¥è®¾å¤‡ä¿¡æ¯
        device_info = inference_engine.get_device_info()
        print(f"\nğŸ“Š è®¾å¤‡ä¿¡æ¯:")
        for key, value in device_info.items():
            print(f"  {key}: {value}")
        
        # è¯¦ç»†æ£€æŸ¥æ¨¡å‹è®¾å¤‡åˆ†å¸ƒ
        print("\nğŸ” INT4æ¨¡å‹è®¾å¤‡åˆ†å¸ƒ:")
        model = inference_engine.model
        
        device_summary = {}
        total_params = 0
        xpu_params = 0
        
        for name, param in model.named_parameters():
            device = str(param.device)
            param_count = param.numel()
            total_params += param_count
            
            if 'xpu' in device.lower():
                xpu_params += param_count
            
            if device not in device_summary:
                device_summary[device] = {'count': 0, 'params': 0, 'memory_mb': 0}
            
            device_summary[device]['count'] += 1
            device_summary[device]['params'] += param_count
            
            # ä¼°ç®—å‚æ•°å†…å­˜å ç”¨ï¼ˆINT4 = 0.5 bytes per paramï¼‰
            if 'int4' in inference_engine.model_path.lower():
                param_memory = param_count * 0.5 / (1024**2)  # MB
            else:
                param_memory = param_count * 2 / (1024**2)  # float16 = 2 bytes per param
            
            device_summary[device]['memory_mb'] += param_memory
        
        print(f"ğŸ“ˆ æ€»å‚æ•°é‡: {total_params:,}")
        
        if xpu_params > 0:
            xpu_percentage = (xpu_params/total_params)*100
            print(f"ğŸ¯ XPUå‚æ•°é‡: {xpu_params:,} ({xpu_percentage:.1f}%)")
        
        for device, info in device_summary.items():
            percentage = (info['params'] / total_params) * 100
            print(f"  {device}:")
            print(f"    - å±‚æ•°: {info['count']}")
            print(f"    - å‚æ•°é‡: {info['params']:,} ({percentage:.1f}%)")
            print(f"    - ä¼°è®¡å†…å­˜: {info['memory_mb']:.1f} MB")
        
        # æ£€æŸ¥XPUä½¿ç”¨æƒ…å†µ
        if hasattr(torch.xpu, 'memory_allocated'):
            allocated = torch.xpu.memory_allocated() / 1024**3
            print(f"ğŸ’¾ XPUæ˜¾å­˜ä½¿ç”¨: {allocated:.2f} GB")
        
        # æ€§èƒ½æµ‹è¯•
        print(f"\nğŸ§ª INT4æ¨¡å‹æ¨ç†æ€§èƒ½æµ‹è¯•...")
        
        # çƒ­èº«æ¨ç†
        print("ğŸ”¥ æ¨¡å‹çƒ­èº«...")
        warmup_start = time.time()
        try:
            test_msgs = [
                {'role': 'user', 'content': ['Warmup test']}
            ]
            
            _ = inference_engine.chat(
                msgs=test_msgs,
                max_new_tokens=5,
                temperature=0.7
            )
            
            warmup_time = time.time() - warmup_start
            print(f"âœ… çƒ­èº«å®Œæˆï¼Œè€—æ—¶: {warmup_time:.2f}ç§’")
            
        except Exception as e:
            print(f"âš ï¸ çƒ­èº«å¤±è´¥: {e}")
            warmup_time = 0
        
        # æ­£å¼æ¨ç†æµ‹è¯•
        print("ğŸš€ æ­£å¼æ¨ç†æµ‹è¯•...")
        test_cases = [
            "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚",
            "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
            "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
        ]
        
        total_inference_time = 0
        successful_tests = 0
        
        for i, question in enumerate(test_cases, 1):
            try:
                print(f"\næµ‹è¯• {i}/{len(test_cases)}: {question}")
                
                test_msgs = [
                    {'role': 'user', 'content': [question]}
                ]
                
                inference_start = time.time()
                
                response = inference_engine.chat(
                    msgs=test_msgs,
                    max_new_tokens=50,
                    temperature=0.7
                )
                
                inference_time = time.time() - inference_start
                total_inference_time += inference_time
                successful_tests += 1
                
                print(f"âœ… å›ç­”: {response}")
                print(f"â±ï¸ æ¨ç†è€—æ—¶: {inference_time:.2f}ç§’")
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        # æ€§èƒ½æ€»ç»“
        if successful_tests > 0:
            avg_inference_time = total_inference_time / successful_tests
            print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
            print(f"  âœ… æˆåŠŸæµ‹è¯•: {successful_tests}/{len(test_cases)}")
            print(f"  â±ï¸ å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.2f}ç§’")
            print(f"  ğŸ æ€»è€—æ—¶: {total_inference_time:.2f}ç§’")
            
            # ä¸åŸæ¨¡å‹æ€§èƒ½å¯¹æ¯”ä¼°ç®—
            print(f"\nğŸ“ˆ INT4é‡åŒ–ä¼˜åŠ¿:")
            print(f"  ğŸ’¾ æ˜¾å­˜èŠ‚çœ: ~75% (ç›¸æ¯”FP16)")
            print(f"  ğŸ“¦ å­˜å‚¨èŠ‚çœ: ~75% (ç›¸æ¯”åŸæ¨¡å‹)")
            print(f"  âš¡ æ¨ç†é€Ÿåº¦: å¯èƒ½ç•¥æ…¢ä½†æ˜¾å­˜å‹å¥½")
        
        return successful_tests > 0
        
    except Exception as e:
        print(f"âŒ INT4æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_video_processing_with_int4():
    """æµ‹è¯•INT4æ¨¡å‹çš„è§†é¢‘å¤„ç†èƒ½åŠ›"""
    try:
        print(f"\nğŸ¥ æµ‹è¯•INT4æ¨¡å‹è§†é¢‘å¤„ç†èƒ½åŠ›...")
        
        from src.chat_with_video.video_chat_service import VideoChatService
        
        # åˆ›å»ºè§†é¢‘èŠå¤©æœåŠ¡ - é»˜è®¤ä½¿ç”¨int4
        service = VideoChatService()
        
        # åˆå§‹åŒ–æœåŠ¡
        if service.initialize():
            print("âœ… INT4è§†é¢‘èŠå¤©æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
            info = service.get_system_info()
            print(f"ğŸ“‹ ç³»ç»Ÿé…ç½®:")
            print(f"  - æ¨¡å‹: {info.get('model_path', 'N/A')}")
            print(f"  - è®¾å¤‡: {info.get('device', 'N/A')}")
            print(f"  - åˆå§‹åŒ–çŠ¶æ€: {info.get('initialized', False)}")
            
            return True
        else:
            print("âŒ INT4è§†é¢‘èŠå¤©æœåŠ¡åˆå§‹åŒ–å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("ğŸ§ª MiniCPM-V-4.5-int4 é‡åŒ–ç‰ˆæœ¬æµ‹è¯•")
    print("="*60)
    
    # åŸºç¡€æ£€æŸ¥
    if not torch.xpu.is_available():
        print("âŒ Intel XPUä¸å¯ç”¨")
        return 1
    
    print(f"âœ… Intel XPUå¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {torch.xpu.device_count()}")
    
    # æµ‹è¯•INT4æ¨¡å‹
    model_success = test_int4_model_loading()
    
    # æµ‹è¯•è§†é¢‘å¤„ç†
    if model_success:
        video_success = test_video_processing_with_int4()
    else:
        video_success = False
    
    # ç»“æœæ€»ç»“
    print("\n" + "="*60)
    if model_success and video_success:
        print("ğŸ‰ INT4é‡åŒ–ç‰ˆæœ¬æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        print("ğŸ“‹ ä¼˜åŠ¿æ€»ç»“:")
        print("  ğŸ’¾ æ˜¾å­˜å ç”¨å¤§å¹…å‡å°‘")
        print("  ğŸ“¦ æ¨¡å‹å­˜å‚¨ç©ºé—´èŠ‚çœ75%")
        print("  âš¡ æ›´é€‚åˆèµ„æºå—é™ç¯å¢ƒ")
        print("  ğŸ¯ åŠŸèƒ½å®Œæ•´ï¼Œæ€§èƒ½è‰¯å¥½")
        print("="*60)
        return 0
    else:
        print("âŒ INT4é‡åŒ–ç‰ˆæœ¬æµ‹è¯•å¤±è´¥!")
        print("="*60)
        return 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)